{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"apoTJfS7Wa3U","colab_type":"code","outputId":"ca57ca61-b9d1-49bb-b454-1e645f6fc5ed","executionInfo":{"status":"ok","timestamp":1571252732087,"user_tz":-330,"elapsed":25943,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yUNKZFJBWfVC","colab_type":"code","outputId":"e0680d55-8162-494e-e843-3cc11877b342","executionInfo":{"status":"ok","timestamp":1571252734658,"user_tz":-330,"elapsed":28063,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["DATASET_PATH = \"/content/drive/My Drive/ire-proj/processedData\"\n","!ls \"$DATASET_PATH\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["articles-training-byarticle.csv    glove.6B.300d.txt\n","articles-training-bypublisher.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y1E3dl4Aw8NK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5SNgt_R4gBr","colab_type":"code","outputId":"f139f64a-29ae-4e5c-a381-4b2850d25c22","executionInfo":{"status":"ok","timestamp":1571252737065,"user_tz":-330,"elapsed":1157,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["df = pd.read_csv(filepath_or_buffer= DATASET_PATH + '/articles-training-byarticle.csv',\n","                 names=['article_id', 'title', 'articleContent', 'hyperpartisan'])\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_id</th>\n","      <th>title</th>\n","      <th>articleContent</th>\n","      <th>hyperpartisan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Kucinich: Reclaiming the money power</td>\n","      <td>From flickr.com: Money {MID-161793} Money ( I...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Trump Just Woke Up &amp; Viciously Attacked Puerto...</td>\n","      <td>Donald Trump ran on many braggadocios and lar...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Liberals wailing about gun control, but what a...</td>\n","      <td>Photo By Justin Sullivan/Getty Images In resp...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Laremy Tunsil joins NFL players in kneeling du...</td>\n","      <td>After Colin Kaepernick rightly chose to kneel ...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>It's 1968 All Over Again</td>\n","      <td>Almost a half-century ago, in 1968, the United...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   article_id  ... hyperpartisan\n","0           0  ...          True\n","1           1  ...          True\n","2           2  ...          True\n","3           3  ...          True\n","4           4  ...         False\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"CFJdEBdT_dv5","colab_type":"code","outputId":"59d5eafa-d522-4a88-a194-67577e6a6f1c","executionInfo":{"status":"ok","timestamp":1571252737568,"user_tz":-330,"elapsed":736,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["df.tail()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_id</th>\n","      <th>title</th>\n","      <th>articleContent</th>\n","      <th>hyperpartisan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>640</th>\n","      <td>640</td>\n","      <td>Trump Turns his Back on American Workers</td>\n","      <td>Donald Trump. Photo from whitehouse.gov. MADI...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>641</th>\n","      <td>641</td>\n","      <td>Cummins: Rescinding DACA ‘discriminatory, harm...</td>\n","      <td>President Donald Trump on Tuesday began disman...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>642</th>\n","      <td>642</td>\n","      <td>Trump travel ban can be enforced, says US Supr...</td>\n","      <td>The US Supreme Court has ruled that Donald Tru...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>643</th>\n","      <td>643</td>\n","      <td>VIDEO- AG SESSIONS: Comey Went Rogue In Hillar...</td>\n","      <td>Ex-FBI Director James Comey went rogue, accord...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>644</th>\n","      <td>644</td>\n","      <td>Hollywood Actors Who Condemn Trump but Were Si...</td>\n","      <td>Ashley Judd is the absolute worst. I want to l...</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     article_id  ... hyperpartisan\n","640         640  ...          True\n","641         641  ...         False\n","642         642  ...         False\n","643         643  ...         False\n","644         644  ...          True\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"2JgTxNAt4j7s","colab_type":"code","outputId":"14d3f18a-41e5-4e8f-95fd-8e072cbb65d4","executionInfo":{"status":"ok","timestamp":1571252738261,"user_tz":-330,"elapsed":731,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(df[df.hyperpartisan==True]), len(df[df.hyperpartisan==False])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(238, 407)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"1i0EWleMpbnm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"5d03cd87-4ada-44a7-aa2f-2504103e3ec8","executionInfo":{"status":"ok","timestamp":1571252739446,"user_tz":-330,"elapsed":966,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["X = df.articleContent.values\n","y = df.hyperpartisan.values\n","X[:1]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' From flickr.com: Money {MID-161793} Money ( Image by 401(K) 2013 ) Permission Details DMCA No Pill Can Stop Tinnitus, But This 1 Weird Trick Can The walls are closing in on Congress. Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in. At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance. Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, the coinage clause, which empowered Congress to coin (create) Money. The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny. The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today. It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money. The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached. In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained. Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders. As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed. With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money. The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system. How To Easily Kill All Indoor Odor, Mold, And Bacteria — Without Lifting A Finger No More Tinnitus (Ear Ringing) If You Do This Immediately In our work on the NEED Act, we propound that the present monetary system has led to a concentration of wealth, expansion of national debt, excessive reliance on taxation, devaluation of the currency, increases in the cost of public infrastructure, unemployment and underemployment and the erosion of the ability of Congress to meet the needs of the American people. This system has been a source of financial instability where the banks ability to create money out of nothing has become a financial liability for the American taxpayers. When banks engaged in speculative lending, turning the financial system into a casino, they were bailed out while millions of Americans lost their homes. No surprise that today we are told there is not enough money for creating jobs, rebuilding America, health care, education and retirement security. But there is always money to bail out the banks. Let us take the opportunity afforded in the debate over the debt ceiling to regain control of our sovereignty and our national destiny. We can have a future of abundance instead of poverty, but we must first take down the wall which separates us from our true sovereignty, the power to coin and create money. Let us return to first principles, and reclaim the constitutional power to coin and create United States money and spend it into circulation to meet the needs of the nation and reduce taxes. Two hundred and thirty years ago this month, delegates from 13 states gathered in a constitutional convention, which set the stage for ratification. Let us summon that same revolutionary spirit and its wisdom to guide us in the days ahead. Seniors Can t Get Enough of This Sweet Treat That Has Shown to Turn Back the Clock on Alzheimer s From flickr.com: Money {MID-161793} Money ( Image by 401(K) 2013 ) Permission Details DMCA The walls are closing in on Congress. Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in. At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance. Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, the coinage clause, which empowered Congress to coin (create) Money. The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny. The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today. It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money. The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached. In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained. Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders. As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed. With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money. The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system. How To Easily Kill All Indoor Odor, Mold, And Bacteria — Without Lifting A Finger Trump to End the Dollar as We Know It by November 8, 2018?'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"gSq4NaWO5UFK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"dd465c62-3079-4c4c-839c-703470fa36a6","executionInfo":{"status":"ok","timestamp":1571252742532,"user_tz":-330,"elapsed":3257,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding\n","from keras.utils import to_categorical\n","import pickle\n","\n","MAX_NB_WORDS=50000 #dictionary size\n","MAX_SEQUENCE_LENGTH=1500 #max word length of each individual article\n","EMBEDDING_DIM=300 #dimensionality of the embedding vector (50, 100, 200, 300)\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n","\n","def tokenize_trainingdata(texts, labels):\n","    tokenizer.fit_on_texts(texts)\n","    pickle.dump(tokenizer, open('tokenizer.p', 'wb'))\n","\n","    sequences = tokenizer.texts_to_sequences(texts)\n","\n","    word_index = tokenizer.word_index\n","    print(f'Found {len(word_index)} unique tokens.')\n","\n","    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","    labels = to_categorical(labels, num_classes=len(set(labels)))\n","\n","    return data, labels, word_index\n","\n","X, y, word_index = tokenize_trainingdata(X, y)    \n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 22423 unique tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hGwfROWqp-0J","colab_type":"code","colab":{}},"source":["#split the data (90% train, 5% test, 5% validation)\n","X_train = X[:int(len(X)*0.9)]\n","y_train = y[:int(len(X)*0.9)]\n","X_test = X[int(len(X)*0.9):int(len(X)*0.95)]\n","y_test = y[int(len(X)*0.9):int(len(X)*0.95)]\n","X_validate = X[int(len(X)*0.95):]\n","y_validate = y[int(len(X)*0.95):]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbuZbdofqfki","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"f80917ef-38ef-43b4-d570-a24a262f5b3f","executionInfo":{"status":"ok","timestamp":1571252743599,"user_tz":-330,"elapsed":971,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["y[:5]   # [0,1] => True(Biased) ; [1,0] => False(Unbiased)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1.],\n","       [0., 1.],\n","       [0., 1.],\n","       [0., 1.],\n","       [1., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"MWO0vh7SquDm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"9cd2b03c-e791-4dbc-d0c8-842d5545514a","executionInfo":{"status":"ok","timestamp":1571252784752,"user_tz":-330,"elapsed":41425,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["def load_embeddings(word_index, embeddingsfile):\n","    embeddings_index = {}\n","    f = open(embeddingsfile, 'r', encoding='utf8')\n","    for line in f:\n","        #here we parse the data from the file\n","        values = line.split(' ') #split the line by spaces\n","        word = values[0] #each line starts with the word\n","        coefs = np.asarray(values[1:], dtype='float32') #the rest of the line is the vector\n","        embeddings_index[word] = coefs #put into embedding dictionary\n","    f.close()\n","\n","    print(f'Found {len(embeddings_index)} word vectors.')\n","\n","    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n","    for word, i in word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            # words not found in embedding index will be all-zeros.\n","            embedding_matrix[i] = embedding_vector\n","    \n","    embedding_layer = Embedding(len(word_index) + 1,\n","                                EMBEDDING_DIM,\n","                                weights=[embedding_matrix],\n","                                input_length=MAX_SEQUENCE_LENGTH,\n","                                trainable=False)\n","    return embedding_layer\n","\n","#and build the embedding layer\n","embedding_layer = load_embeddings(word_index, \n","                                  f'{DATASET_PATH}/glove.6B.{EMBEDDING_DIM}d.txt')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-huH-qQ8vEeJ","colab_type":"code","colab":{}},"source":["from keras import Sequential, Model, Input\n","from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, \\\n","                    GlobalAveragePooling1D, Dropout, LSTM, CuDNNLSTM, RNN, SimpleRNN, Conv2D, GlobalMaxPooling1D\n","from keras import callbacks\n","\n","def baseline_model(sequence_input, embedded_sequences, classes=2):\n","    x = Conv1D(64, 5, activation='relu')(embedded_sequences)\n","    x = MaxPooling1D(5)(x)\n","    x = Conv1D(128, 3, activation='relu')(x)\n","    x = MaxPooling1D(5)(x)\n","    x = Conv1D(256, 2, activation='relu')(x)\n","    x = GlobalAveragePooling1D()(x)\n","    x = Dense(2048, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    preds = Dense(classes, activation='softmax')(x)\n","\n","    model = Model(sequence_input, preds)\n","    return model\n","\n","\n","def LSTM_model(sequence_input, embedded_sequences, classes=2):\n","    x = CuDNNLSTM(32,\n","                  return_sequences=True)(embedded_sequences)\n","    x = CuDNNLSTM(64,\n","                  return_sequences=True)(x)\n","    x = CuDNNLSTM(128)(x)\n","    x = Dense(4096,\n","              activation='relu')(x)\n","    x = Dense(1024,\n","              activation='relu')(x)\n","    preds = Dense(classes,\n","              activation='softmax')(x)\n","\n","    model = Model(sequence_input, preds)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-GaGkqHvIma","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b9232d88-2117-47ec-a7b8-c2621f0ad2ea","executionInfo":{"status":"ok","timestamp":1571252805769,"user_tz":-330,"elapsed":61039,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["#put embedding layer into input of the model\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","model = baseline_model(sequence_input, embedded_sequences, classes=2)\n","# TODO: Test LSTM Model\n","# model = LSTM_model(sequence_input, embedded_sequences, classes=2)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])\n","\n","print(model.summary())\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_validate, y_validate),\n","          epochs=25, batch_size=64)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 1500)              0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 1500, 300)         6727200   \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 1496, 64)          96064     \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 299, 64)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 297, 128)          24704     \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 59, 128)           0         \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 58, 256)           65792     \n","_________________________________________________________________\n","global_average_pooling1d_1 ( (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2048)              526336    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               1049088   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 1026      \n","=================================================================\n","Total params: 8,490,210\n","Trainable params: 1,763,010\n","Non-trainable params: 6,727,200\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 580 samples, validate on 33 samples\n","Epoch 1/25\n","580/580 [==============================] - 5s 8ms/step - loss: 0.6944 - acc: 0.6328 - val_loss: 0.6568 - val_acc: 0.6061\n","Epoch 2/25\n","580/580 [==============================] - 0s 750us/step - loss: 0.6182 - acc: 0.6845 - val_loss: 0.6518 - val_acc: 0.6061\n","Epoch 3/25\n","580/580 [==============================] - 0s 751us/step - loss: 0.5785 - acc: 0.7155 - val_loss: 0.7050 - val_acc: 0.6364\n","Epoch 4/25\n","580/580 [==============================] - 0s 741us/step - loss: 0.5273 - acc: 0.7500 - val_loss: 0.7399 - val_acc: 0.6364\n","Epoch 5/25\n","580/580 [==============================] - 0s 759us/step - loss: 0.4900 - acc: 0.7621 - val_loss: 0.6578 - val_acc: 0.6667\n","Epoch 6/25\n","580/580 [==============================] - 0s 750us/step - loss: 0.4436 - acc: 0.8121 - val_loss: 0.6468 - val_acc: 0.6667\n","Epoch 7/25\n","580/580 [==============================] - 0s 759us/step - loss: 0.4716 - acc: 0.7897 - val_loss: 0.6495 - val_acc: 0.6970\n","Epoch 8/25\n","580/580 [==============================] - 0s 759us/step - loss: 0.4344 - acc: 0.7914 - val_loss: 0.6222 - val_acc: 0.7273\n","Epoch 9/25\n","580/580 [==============================] - 0s 741us/step - loss: 0.3952 - acc: 0.8241 - val_loss: 0.6695 - val_acc: 0.6970\n","Epoch 10/25\n","580/580 [==============================] - 0s 752us/step - loss: 0.4721 - acc: 0.7828 - val_loss: 0.6295 - val_acc: 0.6970\n","Epoch 11/25\n","580/580 [==============================] - 0s 746us/step - loss: 0.3757 - acc: 0.8483 - val_loss: 0.6841 - val_acc: 0.7273\n","Epoch 12/25\n","580/580 [==============================] - 0s 742us/step - loss: 0.3288 - acc: 0.8569 - val_loss: 0.6579 - val_acc: 0.7273\n","Epoch 13/25\n","580/580 [==============================] - 0s 742us/step - loss: 0.2854 - acc: 0.8793 - val_loss: 0.6570 - val_acc: 0.7273\n","Epoch 14/25\n","580/580 [==============================] - 0s 753us/step - loss: 0.2441 - acc: 0.9052 - val_loss: 0.6545 - val_acc: 0.6970\n","Epoch 15/25\n","580/580 [==============================] - 0s 747us/step - loss: 0.1917 - acc: 0.9276 - val_loss: 0.6479 - val_acc: 0.6667\n","Epoch 16/25\n","580/580 [==============================] - 0s 728us/step - loss: 0.1876 - acc: 0.9362 - val_loss: 0.6752 - val_acc: 0.7273\n","Epoch 17/25\n","580/580 [==============================] - 0s 742us/step - loss: 0.1516 - acc: 0.9500 - val_loss: 0.9021 - val_acc: 0.6667\n","Epoch 18/25\n","580/580 [==============================] - 0s 741us/step - loss: 0.1813 - acc: 0.9379 - val_loss: 0.6075 - val_acc: 0.7576\n","Epoch 19/25\n","580/580 [==============================] - 0s 756us/step - loss: 0.0949 - acc: 0.9741 - val_loss: 0.6272 - val_acc: 0.7576\n","Epoch 20/25\n","580/580 [==============================] - 0s 752us/step - loss: 0.0700 - acc: 0.9845 - val_loss: 0.8010 - val_acc: 0.7273\n","Epoch 21/25\n","580/580 [==============================] - 0s 742us/step - loss: 0.0631 - acc: 0.9914 - val_loss: 0.6464 - val_acc: 0.6970\n","Epoch 22/25\n","580/580 [==============================] - 0s 746us/step - loss: 0.0444 - acc: 0.9914 - val_loss: 0.6941 - val_acc: 0.6970\n","Epoch 23/25\n","580/580 [==============================] - 0s 749us/step - loss: 0.0363 - acc: 0.9931 - val_loss: 0.7361 - val_acc: 0.7576\n","Epoch 24/25\n","580/580 [==============================] - 0s 750us/step - loss: 0.0321 - acc: 0.9948 - val_loss: 0.7070 - val_acc: 0.6970\n","Epoch 25/25\n","580/580 [==============================] - 0s 748us/step - loss: 0.0321 - acc: 0.9948 - val_loss: 0.8771 - val_acc: 0.7273\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f161e91c3c8>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"b9kj_pF47lkQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"36509cdb-8703-4adf-cdae-68eb3c654717","executionInfo":{"status":"ok","timestamp":1571252940512,"user_tz":-330,"elapsed":188520,"user":{"displayName":"Abhinav Anand","photoUrl":"","userId":"10775487540525066084"}}},"source":["#put embedding layer into input of the model\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","model = LSTM_model(sequence_input, embedded_sequences, classes=2)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])\n","\n","print(model.summary())\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_validate, y_validate),\n","          epochs=25, batch_size=64)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 1500)              0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 1500, 300)         6727200   \n","_________________________________________________________________\n","cu_dnnlstm_1 (CuDNNLSTM)     (None, 1500, 32)          42752     \n","_________________________________________________________________\n","cu_dnnlstm_2 (CuDNNLSTM)     (None, 1500, 64)          25088     \n","_________________________________________________________________\n","cu_dnnlstm_3 (CuDNNLSTM)     (None, 128)               99328     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4096)              528384    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              4195328   \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 2)                 2050      \n","=================================================================\n","Total params: 11,620,130\n","Trainable params: 4,892,930\n","Non-trainable params: 6,727,200\n","_________________________________________________________________\n","None\n","Train on 580 samples, validate on 33 samples\n","Epoch 1/25\n","580/580 [==============================] - 6s 11ms/step - loss: 0.6585 - acc: 0.6034 - val_loss: 0.6674 - val_acc: 0.6061\n","Epoch 2/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.5752 - acc: 0.7190 - val_loss: 0.6614 - val_acc: 0.5455\n","Epoch 3/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.5664 - acc: 0.6948 - val_loss: 0.6746 - val_acc: 0.5758\n","Epoch 4/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.5041 - acc: 0.7483 - val_loss: 0.7904 - val_acc: 0.6667\n","Epoch 5/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.5067 - acc: 0.7810 - val_loss: 0.5757 - val_acc: 0.6667\n","Epoch 6/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.4290 - acc: 0.8052 - val_loss: 0.7749 - val_acc: 0.6364\n","Epoch 7/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.4294 - acc: 0.8121 - val_loss: 0.6282 - val_acc: 0.6364\n","Epoch 8/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.3564 - acc: 0.8552 - val_loss: 0.7240 - val_acc: 0.6364\n","Epoch 9/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.3395 - acc: 0.8534 - val_loss: 0.6487 - val_acc: 0.6061\n","Epoch 10/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.3063 - acc: 0.8810 - val_loss: 0.7948 - val_acc: 0.6364\n","Epoch 11/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.2901 - acc: 0.8741 - val_loss: 0.7654 - val_acc: 0.7273\n","Epoch 12/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.2650 - acc: 0.9017 - val_loss: 0.8001 - val_acc: 0.6970\n","Epoch 13/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.2143 - acc: 0.9172 - val_loss: 0.7304 - val_acc: 0.6667\n","Epoch 14/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.1648 - acc: 0.9397 - val_loss: 1.0640 - val_acc: 0.6667\n","Epoch 15/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.1631 - acc: 0.9310 - val_loss: 1.0763 - val_acc: 0.6970\n","Epoch 16/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.1647 - acc: 0.9328 - val_loss: 1.1522 - val_acc: 0.7273\n","Epoch 17/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.1219 - acc: 0.9517 - val_loss: 1.4199 - val_acc: 0.6970\n","Epoch 18/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.1259 - acc: 0.9466 - val_loss: 1.0874 - val_acc: 0.6970\n","Epoch 19/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0789 - acc: 0.9707 - val_loss: 0.9867 - val_acc: 0.8182\n","Epoch 20/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0461 - acc: 0.9845 - val_loss: 1.1685 - val_acc: 0.8182\n","Epoch 21/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0578 - acc: 0.9759 - val_loss: 1.7292 - val_acc: 0.6364\n","Epoch 22/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0606 - acc: 0.9759 - val_loss: 1.2383 - val_acc: 0.7576\n","Epoch 23/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0287 - acc: 0.9914 - val_loss: 1.4636 - val_acc: 0.6667\n","Epoch 24/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0225 - acc: 0.9948 - val_loss: 1.4908 - val_acc: 0.7576\n","Epoch 25/25\n","580/580 [==============================] - 5s 9ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 1.4883 - val_acc: 0.7273\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f161e8fd128>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"lt3b-QFS9Orr","colab_type":"code","colab":{}},"source":["y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]}]}